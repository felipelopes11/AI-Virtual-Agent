<img width="456" height="702" alt="img-chat" src="https://github.com/user-attachments/assets/883d2461-4610-41ec-aa27-30288a1343a4" />

‚òï Barista Virtual - Agente de Atendimento com IA
üìù Descri√ß√£o
O Barista Virtual √© uma aplica√ß√£o full-stack que simula um assistente de IA especialista para um e-commerce de caf√©s especiais. O agente √© capaz de responder a perguntas detalhadas sobre os produtos, baseando as suas respostas exclusivamente num cat√°logo de produtos fornecido, evitando "alucina√ß√µes" e garantindo precis√£o.

Este projeto foi constru√≠do para demonstrar a aplica√ß√£o pr√°tica de Modelos de Linguagem Grandes (LLMs) numa solu√ß√£o de neg√≥cio, com foco em IA local, privacidade de dados e uma arquitetura moderna.

‚ú® Funcionalidades Principais
Chat em Tempo Real: Interface de chat reativa constru√≠da com React.

IA Especialista (RAG): Utiliza a t√©cnica de Retrieval-Augmented Generation para fornecer respostas baseadas num cat√°logo de produtos espec√≠fico.

Respostas em Streaming: A resposta da IA √© exibida palavra por palavra, melhorando a experi√™ncia do utilizador.

IA Local e Privada: Executa o modelo de linguagem Llama 3 localmente com o Ollama, garantindo que nenhum dado sens√≠vel √© enviado para APIs externas.

API Robusta: Backend constru√≠do com FastAPI, garantindo alto desempenho e documenta√ß√£o autom√°tica.

üöÄ Tecnologias Utilizadas
Backend
Linguagem: Python

Framework API: FastAPI

Servidor: Uvicorn

Frontend
Biblioteca: React

Ferramenta de Constru√ß√£o: Vite

Comunica√ß√£o API: Axios

Intelig√™ncia Artificial
Modelo (LLM): Llama 3 (via Ollama)

Orquestra√ß√£o: LangChain

Base de Dados Vetorial: ChromaDB

T√©cnica: RAG (Retrieval-Augmented Generation)

üõ†Ô∏è Como Executar o Projeto Localmente
Pr√©-requisitos:

Python 3.10+

Node.js e npm

Ollama instalado e a correr
